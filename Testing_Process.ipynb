{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing Process.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAAnW4PwLapR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dissertation: syntax highlighter for ordinary English text\n",
        "# The last update: 01/09/2019\n",
        "\n",
        "# Please upload BBCdataset.zip and corresponding weights first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stbHZUp48_U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip BBCdataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVuCoT919C2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Dense, Embedding, GRU, Concatenate\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english')) \n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir('BBCdataset') if isfile(join('BBCdataset', f))]\n",
        "total_data = []\n",
        "for i in onlyfiles:\n",
        "    with io.open('BBCdataset/'+i, encoding='utf-8') as f:\n",
        "        # potential encoding problems\n",
        "        try:\n",
        "            data = f.read()\n",
        "            total_data.append(data)\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oW2VeJbLyQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = total_data[-24:]\n",
        "train_data = total_data[:-24]\n",
        "\n",
        "chars = sorted(set(list(''.join(total_data))))\n",
        "# index dict\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coQPh4vS9DBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we provide 3-layered GRU with residual connections model and 3-layered GRU\n",
        "# with residual connections and an embedding layer model\n",
        "# Implementation of Appendix A\n",
        "def residual_GRU():\n",
        "    input_char = Input(shape=(None, len(chars)))\n",
        "    hidden1 = GRU(512, return_sequences=True)(input_char)\n",
        "    concat1 = Concatenate(axis=-1)([input_char, hidden1])\n",
        "    hidden2 = GRU(256, return_sequences=True)(concat1)\n",
        "    concat2 = Concatenate(axis=-1)([hidden1, hidden2])\n",
        "    hidden3 = GRU(128, return_sequences=True, name='target')(concat2)\n",
        "    concat3 = Concatenate(axis=-1)([hidden2, hidden3])\n",
        "    output = Dense(len(chars), activation='softmax')(concat3)\n",
        "    model = Model(input_char, output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def embedding_residual_GRU():\n",
        "    input_char = Input(shape=(None,))\n",
        "    embed = Embedding(88, 64)(input_char)\n",
        "    hidden1 = GRU(512, return_sequences=True)(embed)\n",
        "    concat1 = Concatenate(axis=-1)([embed, hidden1])\n",
        "    hidden2 = GRU(256, return_sequences=True)(concat1)\n",
        "    concat2 = Concatenate(axis=-1)([hidden1, hidden2])\n",
        "    hidden3 = GRU(128, return_sequences=True, name='target')(concat2)\n",
        "    concat3 = Concatenate(axis=-1)([hidden2, hidden3])\n",
        "    output = Dense(len(chars), activation='softmax')(concat3)\n",
        "    model = Model(input_char, output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def vectorize_1(test_para):\n",
        "    '''\n",
        "    one hot encoding\n",
        "    '''\n",
        "    x_pred = np.zeros((1, len(test_para), len(chars)))\n",
        "    for t, char in enumerate(test_para):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "   \n",
        "    return x_pred\n",
        "\n",
        "def vectorize_2(test_para):\n",
        "    '''\n",
        "    dense encoding\n",
        "    '''\n",
        "    indices = [char_indices[char] for char in test_para]\n",
        "    return indices\n",
        "\n",
        "def choose_one_article(test_idx, encoding='non-embedding'):\n",
        "    # choose one article\n",
        "    test_para = test_data[test_idx]\n",
        "    # encoding test_para\n",
        "    if encoding == 'non-embedding':\n",
        "        x_pred = vectorize_1(test_para)\n",
        "        pred = inter_model.predict(x_pred)\n",
        "    elif encoding == 'embedding':\n",
        "        x_pred = vectorize_2(test_para)\n",
        "        pred = inter_model.predict(x_pred).reshape((1,-1,128))\n",
        "    # get outputs\n",
        "    result = []\n",
        "    for i in range(128):        # output dim should be 128\n",
        "        a = list(pred[0][:,i])\n",
        "        result.append(a)    \n",
        "    result.insert(0, list(test_para))\n",
        "    \n",
        "    df = pd.DataFrame(result)\n",
        "    col_name = ['ts'+str(i) for i in list(range(len(test_para)))]\n",
        "    df.columns = col_name\n",
        "    \n",
        "    return test_para, df\n",
        "\n",
        "def choose_all_article(encoding='non-embedding'):\n",
        "    test_para = ''\n",
        "    for each in test_data:\n",
        "        test_para += each\n",
        "        test_para += '\\n'\n",
        "        \n",
        "    if encoding == 'non-embedding':\n",
        "        x_pred = vectorize_1(test_para)\n",
        "        pred = inter_model.predict(x_pred)\n",
        "    elif encoding == 'embedding':\n",
        "        x_pred = vectorize_2(test_para)\n",
        "        pred = inter_model.predict(x_pred).reshape((1,-1,128))\n",
        "    # get outputs\n",
        "    result = []\n",
        "    for i in range(128):        # output dim should be 128\n",
        "        a = list(pred[0][:,i])\n",
        "        result.append(a)    \n",
        "    result.insert(0, list(test_para))\n",
        "    \n",
        "    df = pd.DataFrame(result)\n",
        "    col_name = ['ts'+str(i) for i in list(range(len(test_para)))]\n",
        "    df.columns = col_name\n",
        "    \n",
        "    return test_para, df\n",
        "        \n",
        "def pca_transform(df, proportion):\n",
        "    '''PCA Transformation'''\n",
        "    X = df.T.iloc[:,1:]\n",
        "    pca = PCA(n_components=proportion)\n",
        "    X_reduced = pca.fit_transform(X)\n",
        "    weights = pca.explained_variance_ratio_\n",
        "    \n",
        "    PCAoutputs = []\n",
        "    for i in range(len(pca.explained_variance_ratio_)):\n",
        "        PCAoutputs.append(X_reduced[:,i])\n",
        "        \n",
        "    PCAoutputs.insert(0,list(test_para))\n",
        "    \n",
        "    return pd.DataFrame(PCAoutputs), weights\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoHOMJZT9DGm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose 3-layered GRU with residual connections model for example\n",
        "model = residual_GRU()\n",
        "model.load_weights('residual-GRU.h5')\n",
        "\n",
        "layer_name = 'target'\n",
        "inter_model = Model(inputs=model.input,\n",
        "                    outputs=model.get_layer(layer_name).output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QfKO5JV9DKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one test article\n",
        "test_idx = 6\n",
        "test_para, df = choose_one_article(test_idx, encoding='non-embedding')   \n",
        "df2, weights =  pca_transform(df, 0.6)\n",
        "\n",
        "# To test model performance on hidden state units, use the code below\n",
        "# all test article\n",
        "#test_para, df = choose_all_article(encoding='non-embedding')  \n",
        "#df2, weights =  pca_transform(df, 0.6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQslTMh09DgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = chars[2:]\n",
        "\n",
        "def calculate_mean(df):\n",
        "    '''Implementation of caluculating word-vector'''\n",
        "    res = np.zeros(len(weights),)\n",
        "    count = 0\n",
        "    for i in range(len(df.columns)):\n",
        "        if df.iloc[0, i] in alpha:\n",
        "            res += df.iloc[1:, i]\n",
        "            count += 1\n",
        "        else:\n",
        "            if count == 0:\n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i-count,i):    \n",
        "                    df.iloc[1:, j] = (res/count)\n",
        "                count = 0\n",
        "                res = np.zeros(len(weights),)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMVzEE269Dtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# kmeans\n",
        "# cluster number is derived using the Algorithm One in the dissertation\n",
        "df3 = calculate_mean(df2)\n",
        "X = df3.T.iloc[:,1:]\n",
        "clu_num = 6\n",
        "kmeans = KMeans(n_clusters=clu_num, n_init = 500).fit(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i42vYO7K9DV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df4 = pd.DataFrame([list(df3.iloc[0,:]),\n",
        "                    kmeans.labels_])\n",
        "\n",
        "kmeans_res = [[] for i in range(clu_num)]\n",
        "char = ''\n",
        "for i in range(len(df4.columns)-1):\n",
        "    if int(df4.iloc[1, i]) == int(df4.iloc[1, i+1]):\n",
        "        char += str(df4.iloc[0, i])\n",
        "    else:\n",
        "        char += df4.iloc[0, i]\n",
        "        kmeans_res[int(df4.iloc[1, i])].append(char)\n",
        "        char = ''\n",
        "        \n",
        "# visualize words in all clusters\n",
        "for i in range(clu_num):\n",
        "    print(sorted(set(kmeans_res[i])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjkJzUThzUX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set of kmeans result\n",
        "kmeans_res_set = []\n",
        "for i in range(len(kmeans_res)):\n",
        "    res = list(set(kmeans_res[i]))\n",
        "    kmeans_res_set.append(res)\n",
        "    \n",
        "# do not visualize the cluster with the most words (common words)    \n",
        "maxlen = max([len(i) for i in kmeans_res_set])\n",
        "\n",
        "new_one = []\n",
        "for i in kmeans_res_set:\n",
        "    if len(i) == maxlen:\n",
        "        new_one.append([''])\n",
        "    else:\n",
        "        new_one.append(i)\n",
        "        \n",
        "# remove stop words\n",
        "new_k_res = [[] for i in range(clu_num)]\n",
        "for i in range(len(new_one)):\n",
        "    for word in new_one[i]:\n",
        "        if word.lower() not in stop_words:\n",
        "            new_k_res[i].append(word.strip())  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX8NhbKJ-w9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# visualize the test article\n",
        "paras = test_para.strip().split('\\n\\n')\n",
        "word_list = [paras[i].split() for i in range(len(paras))]\n",
        "\n",
        "total = []\n",
        "for words in word_list:\n",
        "    formats = ''\n",
        "    for word in words:\n",
        "        if word in new_k_res[0]:\n",
        "            color = 'red'             #'Tomato'                         \n",
        "        elif word in new_k_res[1]:\n",
        "            color = 'red'             #'Orange'            \n",
        "        elif word in new_k_res[2]:\n",
        "            color = 'red'             #'DodgerBlue'\n",
        "        elif word in new_k_res[3]:\n",
        "            color = 'red'             #'MediumSeaGreen'\n",
        "        elif word in new_k_res[4]:\n",
        "            color = 'red'             #'SlateBlue'\n",
        "        elif word in new_k_res[5]:\n",
        "            color = 'red'             #'SaddleBrown '\n",
        "        else:\n",
        "            color = 'black'\n",
        "        style = '<span style=\"word-break:break-all; color:' + color + '\">' + word+ '</span>&nbsp;'\n",
        "        formats = formats + style\n",
        "    total.append(formats)\n",
        "    \n",
        "with open ('test.txt', 'w') as f:\n",
        "    for i in total:\n",
        "        style = '<p>'+i+'</p>'\n",
        "        f.write(style)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NJH1Pq0PdRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#####################################\n",
        "# PCA and t-SNE visualization\n",
        "#####################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll-KEAwy-xJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualization on PCA features\n",
        "list1 = [list(kmeans.labels_)]\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    a = list(df3.iloc[i+1, :])\n",
        "    list1.append(a)\n",
        "\n",
        "df_vis = pd.DataFrame(list1)\n",
        "df_vis = df_vis.T\n",
        "\n",
        "# rename columns\n",
        "dict1 = dict()\n",
        "dict1[0] = 'target'\n",
        "for i in range(len(weights)):\n",
        "    dict1[i+1] = 'd'+str(i+1)\n",
        "df_vis.rename( dict1,axis=1, inplace=True)\n",
        "df_vis['target'] = df_vis['target'].apply(lambda x: str(x))\n",
        "# x values\n",
        "feat_cols = list(df_vis.columns[1:])\n",
        "data_subset = df_vis[feat_cols].values\n",
        "\n",
        "# copy of df_vis\n",
        "df_copy = df_vis.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09u9jQeM-xPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(df_vis[feat_cols].values)\n",
        "df_copy['pca-one'] = pca_result[:,0]\n",
        "df_copy['pca-two'] = pca_result[:,1] \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.scatterplot(\n",
        "    x=\"pca-one\", y=\"pca-two\",\n",
        "    hue=\"target\",\n",
        "    palette=sns.color_palette(\"hls\", clu_num),\n",
        "    data=df_copy,\n",
        "    legend=\"full\",\n",
        "    alpha=0.3\n",
        ")\n",
        "\n",
        "plt.savefig('PCA_visualization')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nneTiI-5AjRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tsne\n",
        "import time\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(data_subset)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVFiRYMeAq17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df_copy['tsne-2d-one'] = tsne_results[:,0]\n",
        "df_copy['tsne-2d-two'] = tsne_results[:,1]\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "    hue=\"target\",\n",
        "    palette=sns.color_palette(\"hls\", clu_num),\n",
        "    data=df_copy,\n",
        "    size=0.5,\n",
        "    legend=\"full\",\n",
        "    alpha=1\n",
        ")\n",
        "\n",
        "plt.savefig('tsne_visualization')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shcw3PmyQgok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#############################################\n",
        "# Visualization on hidden state units\n",
        "#############################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRQWNb14rxn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alpha = chars[2:]\n",
        "\n",
        "def calculate_mean1(df):\n",
        "    # calculate mean of each word\n",
        "    res = np.zeros(128,)\n",
        "    count = 0\n",
        "    for i in range(len(df.columns)):\n",
        "        if df.iloc[0, i] in alpha:\n",
        "            res += df.iloc[1:, i]\n",
        "            count += 1\n",
        "        else:\n",
        "            if count == 0:\n",
        "                continue\n",
        "            else:\n",
        "                for j in range(i-count,i):    \n",
        "                    df.iloc[1:, j] = (res/count)\n",
        "                count = 0\n",
        "                res = np.zeros(128,)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpQw0ASJjZbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pca and tsne\n",
        "df3 = calculate_mean1(df)\n",
        "list1 = [list(kmeans.labels_)]\n",
        "\n",
        "for i in range(128):\n",
        "    a = list(df3.iloc[i+1, :])\n",
        "    list1.append(a)\n",
        "\n",
        "df_vis = pd.DataFrame(list1)\n",
        "df_vis = df_vis.T\n",
        "\n",
        "# rename columns\n",
        "dict1 = dict()\n",
        "dict1[0] = 'target'\n",
        "for i in range(128):\n",
        "    dict1[i+1] = 'd'+str(i+1)\n",
        "df_vis.rename( dict1,axis=1, inplace=True)\n",
        "df_vis['target'] = df_vis['target'].apply(lambda x: str(x))\n",
        "# x values\n",
        "feat_cols = list(df_vis.columns[1:])\n",
        "data_subset = df_vis[feat_cols].values\n",
        "\n",
        "# copy of df_vis\n",
        "df_copy = df_vis.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXmoZJdLkwVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca_result = pca.fit_transform(df_copy[feat_cols].values)\n",
        "df_copy['pca-one'] = pca_result[:,0]\n",
        "df_copy['pca-two'] = pca_result[:,1] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvccTFXYtegb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.scatterplot(\n",
        "    x=\"pca-one\", y=\"pca-two\",\n",
        "    hue=\"target\",\n",
        "    palette=sns.color_palette(\"hls\", clu_num),\n",
        "    data=df_copy,\n",
        "    legend=\"full\",\n",
        "    alpha=0.3\n",
        ")\n",
        "plt.savefig('PCA_hidden unit')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J7kH54kkwbD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "time_start = time.time()\n",
        "tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
        "tsne_results = tsne.fit_transform(data_subset)\n",
        "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I7vxR78NQ6xH",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df_copy['tsne-2d-one'] = tsne_results[:,0]\n",
        "df_copy['tsne-2d-two'] = tsne_results[:,1]\n",
        "plt.figure(figsize=(8,8))\n",
        "sns.scatterplot(\n",
        "    x=\"tsne-2d-one\", y=\"tsne-2d-two\",\n",
        "    hue=\"target\",\n",
        "    palette=sns.color_palette(\"hls\", clu_num),\n",
        "    data=df_copy,\n",
        "    legend=\"full\",\n",
        "    alpha=0.3,\n",
        "    size=0.3\n",
        ")\n",
        "\n",
        "plt.savefig('t-SNE_hidden unit')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}