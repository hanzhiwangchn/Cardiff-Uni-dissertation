{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Training Process.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ythdBeF3UbNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dissertation: syntax highlighter for ordinary English text\n",
        "# The last update: 01/09/2019\n",
        "\n",
        "# Please upload BBCdataset.zip first"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQIJMPewM6bI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip BBCdataset.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbzDxIQQU63b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Dense, Embedding, GRU, Concatenate\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import io\n",
        "\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir('BBCdataset') if isfile(join('BBCdataset', f))]\n",
        "\n",
        "total_data = []\n",
        "for i in onlyfiles:\n",
        "    with io.open('BBCdataset/'+i, encoding='utf-8') as f:\n",
        "        # potential encoding problems\n",
        "        try:\n",
        "            data = f.read()\n",
        "            total_data.append(data)\n",
        "        except:\n",
        "            continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XD7_71EWvsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = total_data[-24:]\n",
        "train_data = total_data[:-24]\n",
        "\n",
        "chars = sorted(set(list(''.join(total_data))))\n",
        "# index dict\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wEaWwNSfCN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we provide 3-layered GRU with residual connections model and 3-layered GRU\n",
        "# with residual connections and an embedding layer model\n",
        "# Implementation of Appendix A\n",
        "def residual_GRU():\n",
        "    input_char = Input(shape=(None, len(chars)))\n",
        "    hidden1 = GRU(512, return_sequences=True)(input_char)\n",
        "    concat1 = Concatenate(axis=-1)([input_char, hidden1])\n",
        "    hidden2 = GRU(256, return_sequences=True)(concat1)\n",
        "    concat2 = Concatenate(axis=-1)([hidden1, hidden2])\n",
        "    hidden3 = GRU(128, return_sequences=True, name='target')(concat2)\n",
        "    concat3 = Concatenate(axis=-1)([hidden2, hidden3])\n",
        "    output = Dense(len(chars), activation='softmax')(concat3)\n",
        "    model = Model(input_char, output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def embedding_residual_GRU():\n",
        "    input_char = Input(shape=(None,))\n",
        "    embed = Embedding(88, 64)(input_char)\n",
        "    hidden1 = GRU(512, return_sequences=True)(embed)\n",
        "    concat1 = Concatenate(axis=-1)([embed, hidden1])\n",
        "    hidden2 = GRU(256, return_sequences=True)(concat1)\n",
        "    concat2 = Concatenate(axis=-1)([hidden1, hidden2])\n",
        "    hidden3 = GRU(128, return_sequences=True, name='target')(concat2)\n",
        "    concat3 = Concatenate(axis=-1)([hidden2, hidden3])\n",
        "    output = Dense(len(chars), activation='softmax')(concat3)\n",
        "    model = Model(input_char, output)\n",
        "    \n",
        "    return model\n",
        "\n",
        "def encoding_input_output(structure):\n",
        "    if structure == 'non-embedding':\n",
        "        x = np.zeros((len(prev_sentences), maxlen, len(chars)))\n",
        "        y = np.zeros((len(next_sentences), maxlen, len(chars)))     \n",
        "        for i, sentence in enumerate(prev_sentences):\n",
        "            for t, char in enumerate(sentence):\n",
        "                x[i, t, char_indices[char]] = 1         \n",
        "        for i, sentence in enumerate(next_sentences):\n",
        "            for t, char in enumerate(sentence):\n",
        "                y[i, t, char_indices[char]] = 1        \n",
        "        return x, y\n",
        "    \n",
        "    elif structure == 'embedding':\n",
        "        x = []\n",
        "        for i in prev_sentences:\n",
        "            indices = [char_indices[char] for char in i]\n",
        "            x.append(indices)\n",
        "        x = np.array(x) \n",
        "        y = np.zeros((len(next_sentences), maxlen, len(chars)))\n",
        "        for i, sentence in enumerate(next_sentences):\n",
        "            for t, char in enumerate(sentence):\n",
        "                y[i, t, char_indices[char]] = 1        \n",
        "        return x, y "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6VM5c7YgKti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# choose 3-layered GRU with residual connections model for example\n",
        "model = residual_GRU()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuG4AKmdgXWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cut the text in sequences of maxlen characters to create training data\n",
        "maxlen = 100\n",
        "step = 40\n",
        "prev_sentences = []\n",
        "next_sentences = []\n",
        "for i in train_data:\n",
        "    for j in range(0, len(i) - maxlen, step):\n",
        "        prev_sentences.append(i[j: j+maxlen])\n",
        "        next_sentences.append(i[j+1: j+maxlen+1])\n",
        "print('number sequences:', len(prev_sentences))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7YSNTIz6vj7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encoding the inputs\n",
        "x, y = encoding_input_output('non-embedding')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuRye3-8g45m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "adam = Adam(amsgrad=True)\n",
        "early_stopping_cb = EarlyStopping(patience=3, \n",
        "                                  monitor='val_loss',\n",
        "                                  restore_best_weights=True)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x, y,\n",
        "                    batch_size=64, epochs=100,\n",
        "                    validation_split = 0.05,\n",
        "                    callbacks=[early_stopping_cb])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}